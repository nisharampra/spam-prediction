{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Encode labels (spam = 1, ham = 0)\n",
        "data['label'] = data['label'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text to numerical data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pVz0HJj1Aui",
        "outputId": "d9862753-d19a-4b8c-e51e-018469e9c28d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.979372197309417\n",
            "Precision: 0.9921875\n",
            "Recall: 0.8523489932885906\n",
            "F1 Score: 0.9169675090252708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify new messages\n",
        "def classify_message(message, model, vectorizer):\n",
        "    processed_message = vectorizer.transform([message])  # Preprocess the input message\n",
        "    prediction = model.predict(processed_message)\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Ham\"\n",
        "\n",
        "# Example usage\n",
        "new_message = \"Congratulations! You've won a $1,000 Walmart gift card. Call now!\"\n",
        "result = classify_message(new_message, model, vectorizer)\n",
        "print(f\"The message is: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nXcICXQ1KbF",
        "outputId": "c3a61b30-ad18-4e83-baba-0af1608d1a1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The message is: Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify new messages\n",
        "def classify_message(message, model, vectorizer):\n",
        "    processed_message = vectorizer.transform([message])  # Preprocess the input message\n",
        "    prediction = model.predict(processed_message)\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Ham\"\n",
        "\n",
        "# Example usage\n",
        "new_message = \"hi you can pass this exam\"\n",
        "result = classify_message(new_message, model, vectorizer)\n",
        "print(f\"The message is: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUfkeRM01Oyq",
        "outputId": "0214e8dc-ca95-49b1-80e9-d8183f043fe9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The message is: Ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify new messages\n",
        "def classify_message(message, model, vectorizer):\n",
        "    processed_message = vectorizer.transform([message])  # Preprocess the input message\n",
        "    prediction = model.predict(processed_message)\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Ham\"\n",
        "\n",
        "# Example usage\n",
        "new_message = \"Hey, are we still meeting for lunch tomorrow?\"\n",
        "result = classify_message(new_message, model, vectorizer)\n",
        "print(f\"The message is: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e26849f-9bbf-4bd5-d3e8-390a77536a38",
        "id": "xyJpJigh1fbi"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The message is: Ham\n"
          ]
        }
      ]
    }
  ]
}